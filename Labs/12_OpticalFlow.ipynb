{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d0b08c",
   "metadata": {},
   "source": [
    "# CSCI E-25 \n",
    "## Optical Flow   \n",
    "### Steve Elston"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc4846b-933e-43de-af70-d6c3b8a74e88",
   "metadata": {},
   "source": [
    "In this assignment you will perform a exercises concerning optical flow. Code is provided and you are to answer the questions in the exercises. \n",
    "\n",
    " These exercises are derived from an [example in the Scikit Image User Guide](https://scikit-image.org/docs/stable/auto_examples/registration/plot_opticalflow.html).\n",
    "\n",
    "> Note: Before you proceed you may need to update the version of scikit-image and the Pooch package. To do so, uncomment and execute the code in the cell below. Then shut down your Jupyter server and restart.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c83919-46b0-42cd-8398-288d5009e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade scikit-image\n",
    "#!pip install pooch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bcc2ec-18c6-40b1-82be-b21093499900",
   "metadata": {},
   "source": [
    "To get started, execute the code in the cell below to import the packages you will need for this notebook.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96362e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.data import stereo_motorcycle, vortex\n",
    "from skimage.transform import warp\n",
    "from skimage.registration import optical_flow_tvl1, optical_flow_ilk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70550dc4",
   "metadata": {},
   "source": [
    "## Iterative Lucas-Kanade (iLK) Algorithm\n",
    "\n",
    "As a first simple example, you will apply the **iterative Lucas-Kanade** algorithm to a random field image. The random field image is generated by computing random pixel values. A second image is created by rotating the first around an axis in the image field. The goal is to register these two images and compute and display the optical flow field.   \n",
    "\n",
    "Now, execute the code in the cell below to load and display the two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grayscale(img, h=8, ax=None, title = ''):\n",
    "    if(ax==None): fig, ax = plt.subplots(1,1, figsize=(h, h))\n",
    "    _=ax.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "    _=ax.set_title(title)\n",
    "    _=ax.axis('off');\n",
    "\n",
    "\n",
    "image0, image1 = vortex()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "plot_grayscale(image0, ax=ax[0], title='image0')\n",
    "plot_grayscale(image1, ax=ax[1], title='image1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd489679",
   "metadata": {},
   "source": [
    "> **Exercise 12-1:** The iLK algorithm uses no smoothness constraint for regularization, imposing only the constant flow constraint. In a sentence of two, explain why for rough (random field) image the ikL algorithm with no smoothness constraint is a good choice.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82332020",
   "metadata": {},
   "source": [
    "> **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b105b7",
   "metadata": {},
   "source": [
    "You will now compute the optical flow components using iLK algorithm provided by [skimage.registration.optical_flow_ilk](https://scikit-image.org/docs/stable/api/skimage.registration.html#skimage.registration.optical_flow_ilk). The code in the cell below does the follow operations:  \n",
    "\n",
    "1. Compute the horizontal and vertical optical flow between the two images. \n",
    "2. Compute the Euclidean norm of the flow field. \n",
    "3. Plot the results.\n",
    "\n",
    "Execute this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the optical flow\n",
    "v, u = optical_flow_ilk(image0, image1, radius=15)\n",
    "# Compute flow magnitude\n",
    "norm = np.sqrt(u ** 2 + v ** 2)\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(16,16))\n",
    "plot_grayscale(v, ax=ax[0,0], title='Vertical flow')\n",
    "plot_grayscale(u, ax=ax[0,1], title='Horizontal flow')\n",
    "plot_grayscale(norm, ax=ax[1,0], title='Norm of flow')\n",
    "ax[1,1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd734e31",
   "metadata": {},
   "source": [
    "With the flow field computed, it is instructive to display the examine the vector flow field. The code in the cell below does just this using the quiver plot function [matplotlib.pyplot.quiver](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.quiver.html). Execute this code and examine the result.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b82327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiver plot arguments\n",
    "nvec = 20  # Number of vectors to be displayed along each image dimension\n",
    "nl, nc = image0.shape\n",
    "step = max(nl//nvec, nc//nvec)\n",
    "\n",
    "y, x = np.mgrid[:nl:step, :nc:step]\n",
    "u_ = u[::step, ::step]\n",
    "v_ = v[::step, ::step]\n",
    "\n",
    "plt.imshow(norm)\n",
    "plt.quiver(x, y, u_, v_, color='r', units='dots',\n",
    "           angles='xy', scale_units='xy', lw=3)\n",
    "plt.title(\"Optical flow magnitude and vector field\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae9660",
   "metadata": {},
   "source": [
    "> **Exercise 12-2:** Examine the plots of the horizontal flow, vertical flow, Euclidean norm of flow and the quiver plot of the flow field. Keep in mind that for the gray-scale images of flow a bright (light) value is strongly positive and a dark value is strongly negative. In a few sentences, answer the following questions.     \n",
    "> 1. How does the flow field change as you move away from the axis of rotation?  \n",
    "> 2. Are the different figures showing the flow field consistent and why? Hint; compare the vector flow to the images of horizontal and vertical flow as well as the norm of the flow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2828e1a",
   "metadata": {},
   "source": [
    "> **Answers:** \n",
    "> 1.    \n",
    "> 2.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2e994",
   "metadata": {},
   "source": [
    "## TV-L1 Algorithm\n",
    "\n",
    "You will now work with an improved version of the TV-L1 algorithm. Here you will examine the optical flow between two time-sequential images. This image data set comes with ground truth.   \n",
    "\n",
    "Execute the code in the cell below to load the  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b698ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sequence of images and displacement\n",
    "image0, image1, disp = stereo_motorcycle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b15d7",
   "metadata": {},
   "source": [
    "The code in the cell below displays the two images, along with the Euclidean norm of ground truth displacement. Execute this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6347c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image0 = rgb2gray(image0)\n",
    "image1 = rgb2gray(image1)\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(16,12))\n",
    "plot_grayscale(image0, ax=ax[0,0], title='image0')\n",
    "plot_grayscale(image1, ax=ax[0,1], title='image1')\n",
    "plot_grayscale(disp, ax=ax[1,0], title='Displacement ground truth')  \n",
    "ax[1,1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b4f97",
   "metadata": {},
   "source": [
    "The lighter the pixel in the displacement image the greater the displacement. \n",
    "\n",
    "Another way to view the displacement between these images is by applying an optical trick. A 3-channel (RGB) image is created from the gray-scale images. The second (displaced) image is placed in the first channel. The first (reference) image is placed in the second and third channel. In this way, displacements can be seen as red-green shadows. Execute the code in the cell below and examine the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329cd3b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DisplacementTORGB(image0, image1):\n",
    "    nr,nc = image0.shape\n",
    "    seq_im = np.zeros((nr, nc, 3))\n",
    "    seq_im[..., 0] = image1\n",
    "    seq_im[..., 1] = image0\n",
    "    seq_im[..., 2] = image0\n",
    "    return(seq_im)\n",
    "\n",
    "plot_grayscale(DisplacementTORGB(image0, image1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8c50ec",
   "metadata": {},
   "source": [
    "The code in the cell below performs the following operations:  \n",
    "1. Computes the optical flow between the two images using the TV-L1 algorithm provided by the [skimage.registration.optical_flow_tvl1](https://scikit-image.org/docs/stable/api/skimage.registration.html#skimage.registration.optical_flow_tvl1) function. \n",
    "2. Computes norm of the flow field vectors. \n",
    "3. Computes the pixel-by-pixel end-point error, filter for infinite values (from zero divides), and print the average end-point error. \n",
    "4. Display the vertical flow field, horizontal flow field, Euclidean norm of the flow, displacement ground truth, and end-point error field. \n",
    "\n",
    "Execute the code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df441f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "v, u = optical_flow_tvl1(image0, image1)\n",
    "\n",
    "flow_norm = np.sqrt(u ** 2 + v ** 2)\n",
    "\n",
    "endpoint_error = np.sqrt(np.square(flow_norm - disp))\n",
    "endpoint_error[endpoint_error==np.Inf] = 0.0\n",
    "print('Average end-point error = ' + str(np.mean(endpoint_error)))\n",
    "\n",
    "fig, ax = plt.subplots(3,2, figsize=(16,18))\n",
    "plot_grayscale(v, ax=ax[0,0], title='Vertical flow')\n",
    "plot_grayscale(u, ax=ax[0,1], title='Horizontal flow')\n",
    "plot_grayscale(flow_norm, ax=ax[1,0], title='Norm of flow')\n",
    "plot_grayscale(disp, ax=ax[1,1], title='Displacement ground truth')  \n",
    "plot_grayscale(endpoint_error, ax=ax[2,0], title='End-point error field')  \n",
    "ax[2,1].axis('off')\n",
    "ax[2,1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c4117",
   "metadata": {},
   "source": [
    "> **Exercise 12-3:** Examine these results and answer the following questions in one or two sentences.  \n",
    "> 1. This the estimated flow more vertical or horizontal, and how can you tell?  \n",
    "> 2. What portion of the image exhibits the greatest error in the flow field and how can you tell.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f2ebe",
   "metadata": {},
   "source": [
    "> **Answers:**\n",
    "> 1.    \n",
    "> 2.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6489a",
   "metadata": {},
   "source": [
    "Next, execute the code in the code to display the original image first image, the warped second image, and the registered image created with the first image warped second image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a66869",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr, nc = image0.shape\n",
    "row_coords, col_coords = np.meshgrid(np.arange(nr), np.arange(nc), indexing='ij')\n",
    "image1_warp = warp(image1, np.array([row_coords + v, col_coords + u]),mode='edge')\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(16,12))\n",
    "plot_grayscale(DisplacementTORGB(image0, image0), ax=ax[0,0], title = 'Original image')\n",
    "plot_grayscale(image1_warp, ax=ax[0,1], title = 'Warped image')\n",
    "plot_grayscale(DisplacementTORGB(image0, image1_warp), ax=ax[1,0], title = 'Registered image')\n",
    "ax[1,1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fcd96c",
   "metadata": {},
   "source": [
    "> **Exercise 12-4:** Examine these results. Where are the largest registration errors and are these consistent with the flow errors you investigated in Exercise 12-3? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e141dc",
   "metadata": {},
   "source": [
    "> **Answers:**       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421d3b1",
   "metadata": {},
   "source": [
    "Next, you will repeat the steps of computing characteristics of the optical flow, but using the a larger parameter value, $\\lamda$, 150, vs. the default value of 15 used in the first example. The larger parameter value favors brightness continuity. Execute the code and examine the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v, u = optical_flow_tvl1(image0, image1, attachment=150)\n",
    "\n",
    "flow_norm = np.sqrt(u**2 + v**2)\n",
    "\n",
    "endpoint_error = np.sqrt(np.square(flow_norm - disp))\n",
    "endpoint_error[endpoint_error==np.Inf] = 0.0\n",
    "print('Average end-point error = ' + str(np.mean(endpoint_error)))\n",
    "\n",
    "fig, ax = plt.subplots(3,2, figsize=(16,18))\n",
    "plot_grayscale(v, ax=ax[0,0], title='Vertical flow')\n",
    "plot_grayscale(u, ax=ax[0,1], title='Horizontal flow')\n",
    "plot_grayscale(flow_norm, ax=ax[1,0], title='Norm of flow')\n",
    "plot_grayscale(disp, ax=ax[1,1], title='Displacement ground truth')  \n",
    "plot_grayscale(endpoint_error, ax=ax[2,0], title='End-point error field')  \n",
    "ax[2,1].axis('off')\n",
    "ax[2,1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55641392",
   "metadata": {},
   "source": [
    "> **Exercise 12-5:** Compare these results to the results with smaller value of $\\lambda$ and answer the following these questions in one or two sentences.      \n",
    "> 1. Comparing the average end-point errors, which value of $\\lambda$ provides a better result?    \n",
    "> 2. What differences can you see in the flow field images and is this expected given the value change in $\\lambda$?    \n",
    "> 3. What differences can you see in the end-point error fields between the two values of $\\lambda$?    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1c45e",
   "metadata": {},
   "source": [
    "> **Answers:**   \n",
    "> 1.    \n",
    "> 2.    \n",
    "> 3.      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea8c511",
   "metadata": {},
   "source": [
    "Finally, execute the code in the code in the cell below to display the registration of the first image with the warped second image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42c41f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_coords, col_coords = np.meshgrid(np.arange(nr), np.arange(nc), indexing='ij')\n",
    "image1_warp = warp(image1, np.array([row_coords + v, col_coords + u]),mode='edge')\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(16,12))\n",
    "plot_grayscale(DisplacementTORGB(image0, image0), ax=ax[0,0], title = 'Original image')\n",
    "plot_grayscale(image1_warp, ax=ax[0,1], title = 'Warped image')\n",
    "plot_grayscale(DisplacementTORGB(image0, image1_warp), ax=ax[1,0], title = 'Registered image')\n",
    "ax[1,1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1207b",
   "metadata": {},
   "source": [
    "These results are not particularly different from the first set. This is expected from the minimal change in average end-point error. While not great, you should be able to see that the error is in fact a bit less around the front wheel of the motorcycle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3205c-8510-4bf6-9c05-10bc64e2a360",
   "metadata": {},
   "source": [
    "> **Exercise 12-6:** Scale is an important difficulty in computing optical flow fields. Answer the following questions in one or a few sentances.  \n",
    "> 1. Describe a real world situation where a large difference is scale occurs in a flow field.  \n",
    "> 2. What is a common approach to working with multiple scale in both conventional and neural flow field algorithms? What is the difference between the algorithm used in conventional and neural algorithms?  \n",
    "> 3. In one or a few sentances explain the roles of the two flow scales in the NeuFlow 2 algorithm and how the scales are used to compute the final flow field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dac756-e2fc-45d9-bbc8-ee888e478772",
   "metadata": {},
   "source": [
    "> **Answers:**\n",
    "> 1.     \n",
    "> 2.    \n",
    "> 3.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9abf9d9-6c40-46f9-bcc0-7c8bfc66006f",
   "metadata": {},
   "source": [
    "> **Exercise 12-7:** Neural network optical flow algorithms often use a correlation volume. In one or a few sentances answer the following wuestions.    \n",
    "> 1. Describe the nature and purpose of the corrlation volume data structure.   \n",
    "> 2. How will low gradient areas affect the calculations requried for the correlation volume?    \n",
    "> 3. How does the use of multi-scale flow help mitagate the affect of low gradient areas of the image?     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d473d45-ec64-473e-a344-82b8b3eb7d4c",
   "metadata": {},
   "source": [
    "> **Answer:**\n",
    "> 1.    \n",
    "> 2.     \n",
    "> 3.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1a4020",
   "metadata": {},
   "source": [
    "#### Copyright 2022, 2024. 2025, Stephen F Elston. All rights reserved. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
