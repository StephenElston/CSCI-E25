{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827f432e-ff64-467e-a648-a124a03e6fc4",
   "metadata": {},
   "source": [
    "# Introduction to Denoising Diffusion Implicit Generative Models\n",
    "\n",
    "## Stephen Elston\n",
    "\n",
    "## Overview\n",
    "\n",
    "Though these exercises you will gain some basic understanding of **denoising deffusion implicit models (DDIMs)**. DDIMs are image generative models which synthesize high quality images.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c928db3-3443-4e2a-9e4e-687017305e6d",
   "metadata": {},
   "source": [
    "## Running the Example Code     \n",
    "\n",
    "For the exercises you will first need to run the code in this [Keras example notebook by Andres Beres](https://keras.io/examples/generative/ddim/). To run the notebook you will need a [Google Colabratory account](https://colab.research.google.com/) if you do not already have one. Log into your google account. From the Keras example page click the `View in Colab` tab to start the notebook in Colab (but do not execute yet!). Alternatively, you may want to run this notebook locally, if you have the resources.     \n",
    "\n",
    "On several tests with Colab and Colab Pro+ this notebook executed in under 1 hour with no time outs. If you enconter problems, please reach out to the instructional staff.  \n",
    "\n",
    "The next section outlines changes you will need to make in this notebook.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ea94e-1192-4e2b-af31-26dce65bf2e1",
   "metadata": {},
   "source": [
    "## Configuring Runtime\n",
    "\n",
    "It is recommended that you configure your at either of:     \n",
    "- L4 GPU\n",
    "- T4 GPU\n",
    "\n",
    "Use `High-RAM`.   \n",
    "\n",
    "If you wish to change the runtime environment, use the pulldown to display this box, from which you can select your runtime.   \n",
    "\n",
    "<img src=\"../img/ColabChangeRuntime.png\" alt=\"Drawing\" style=\"width:500px; height:300px\"/>\n",
    "<center>Box for configuring Colab runtime environment</center>     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2c9f9-47d9-4873-a51b-7de6d2aaa9b7",
   "metadata": {},
   "source": [
    "## Updates to the Code\n",
    "\n",
    "The Denoising Diffusion Implicit Modle notebook available in Keras Examples was created using Keras 2.X. Modifications are required to run this notebook under Keras 3.X. Please make the indicated updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b414a2-345a-478b-9520-03dfdbe09b70",
   "metadata": {},
   "source": [
    "### 1. Verify versions of TensorFlow and Keras\n",
    "\n",
    "To ensure that you are using TensorFlow verion 2.18.0 or above and Keras version 3.8.0 or above add the code in the cell below to the end or the code cell with the imports.   "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ed16f80-4ae8-4fc0-a735-bb9eb79af345",
   "metadata": {},
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da82de-4b94-498d-bd97-585d0f412440",
   "metadata": {},
   "source": [
    "### 2. Add call methods to Diffusion Model    \n",
    "\n",
    "The last method defined in the notebook for the `DiffusionModel` class is `plot_images`. To run under Keras 3.8 an explicit `call` method must be added. Append the code shown below to the code for the `DiffusionModel` class. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "47d0be8a-5d96-4f8f-8fb7-5e754f627a7b",
   "metadata": {},
   "source": [
    "    def call(self, inputs, training=False):\n",
    "        ## Method for the forward pass of the diffusion model\n",
    "        noisy_images, noise_rates = inputs\n",
    "        _, signal_rates = self.diffusion_schedule(noise_rates)  # Calculate signal rates from noise rates\n",
    "        ## Return the denoised result\n",
    "        return self.denoise(noisy_images, noise_rates, signal_rates, training=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50288cd4-db1a-43e5-b385-6469d1aed17e",
   "metadata": {},
   "source": [
    "### 3. Add explicity model building step and capture training history   \n",
    "\n",
    "To run this notebook with Keras 3.8 the model must be built explicitly. Code to build the model is added following the compile step in the cell below.  \n",
    "\n",
    "In order to investigate the training further, the history is saved in dictionary named `train_history`.\n",
    "\n",
    "The code in the cell below should replace the code in the **Trsaining** section of the notebook.   "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee5bf43b-4402-42bc-bc3b-4f863e44af2d",
   "metadata": {},
   "source": [
    "# create and compile the model\n",
    "model = DiffusionModel(image_size, widths, block_depth)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    ),\n",
    "    loss=keras.losses.mean_absolute_error,\n",
    ")\n",
    "# pixelwise mean absolute error is used as loss\n",
    "\n",
    "# Build the model by calling it on a batch of data\n",
    "# This will initialize the weights and allow the model to be saved\n",
    "for images in train_dataset.take(1):\n",
    "    # Generate random noise rates for the batch of images\n",
    "    noise_rates = tf.random.uniform(shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0)\n",
    "\n",
    "    # Call the model with both images and noise rates\n",
    "    model([images, noise_rates])\n",
    "\n",
    "# save the best model based on the validation KID metric\n",
    "checkpoint_path = \"checkpoints/diffusion_model.weights.h5\"\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_kid\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "# calculate mean and variance of training dataset for normalization\n",
    "model.normalizer.adapt(train_dataset)\n",
    "\n",
    "## Build the model \n",
    "model.build(input_shape=(None,64,64,3))\n",
    "\n",
    "# run training and plot generated images periodically\n",
    "train_history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[\n",
    "        keras.callbacks.LambdaCallback(on_epoch_end=model.plot_images),\n",
    "        checkpoint_callback,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c3fe8-2396-4d48-a725-cef06d1bb14a",
   "metadata": {},
   "source": [
    "### 4. Plotting the training history\n",
    "\n",
    "To display the training history for the model add a new code cell below the cell with the training code. Paste the code shown below into this cell.    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe73c648-ace5-449b-8dbf-b63e3f0dae19",
   "metadata": {},
   "source": [
    "def plot_image_loss(history, ax=None):\n",
    "    '''Function to plot the image loss vs. epoch'''\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(4, 3))\n",
    "    train_i_loss = history.history['i_loss']\n",
    "    val_i_loss = history.history['val_i_loss']\n",
    "    x = list(range(1, len(val_i_loss) + 1))\n",
    "    ax.plot(x, val_i_loss, color = 'red', label = 'Validation image loss')\n",
    "    ax.plot(x, train_i_loss, label = 'Train image losss')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Image Loss')\n",
    "    ax.set_title('Image Loss vs. Epoch')\n",
    "    plt.show()\n",
    "\n",
    "def plot_noise_loss(history, ax=None):\n",
    "    '''Function to plot the noise loss vs. epoch'''\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(4, 3))\n",
    "    train_n_loss = history.history['n_loss']\n",
    "    val_n_loss = history.history['val_n_loss']\n",
    "    x = list(range(1, len(val_n_loss) + 1))\n",
    "    ax.plot(x, val_n_loss, color = 'red', label = 'Validation noise loss')\n",
    "    ax.plot(x, train_n_loss, label = 'Train noise losss')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Noise Loss')\n",
    "    ax.set_title('Noise Loss vs. Epoch')\n",
    "    plt.show()\n",
    "\n",
    "def plot_kid(history,  ax=None):\n",
    "    '''Function to plot the KID vs. epoch'''\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(4, 3))\n",
    "    kid = history.history['val_kid']\n",
    "    x = list(range(1, len(kid) + 1))\n",
    "    ax.plot(x, kid, label = 'Validatio KID')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Validation KID')\n",
    "    ax.set_title('Validation KID vs. Epoch')\n",
    "    plt.show()\n",
    " \n",
    "plot_image_loss(train_history) #, ax=ax[0])\n",
    "plot_noise_loss(train_history) #, ax=ax[1])\n",
    "plot_kid(train_history) #, ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186cf020-d019-4bf2-873b-c8021fbbe60c",
   "metadata": {},
   "source": [
    "## Exercises     \n",
    "\n",
    "With the notebook updated carefully read the explainatory text provided by the author. Then, execute the code and answer the questions in the following exercises.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498ff711-6e54-4bc5-827d-277f40a211c8",
   "metadata": {},
   "source": [
    "> **Exercise 11-1:** In the DiffusionModel class examine the code in the `diffusion_schedule` method. Also, read the discussion in the diffusion schedule subsection of the text. What can you say about the rate of the increase of the added noise, $\\epsilon_t$, in the steps of the forward diffusion process?                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d5eb0d-6796-4703-a1bf-4905ec8c1ef9",
   "metadata": {},
   "source": [
    "> **Answers:**          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59df21-be01-49c7-aca6-857eaf6b8d07",
   "metadata": {},
   "source": [
    "> **Exercise 11-2:** Examine the code in the `denoise` method. This method is called at each revserse diffusion step in the `reverse_diffusion` method. Notice the if statement that switches btween training the neural network or sampling. Answer the following questions:    \n",
    "> 1. During training, what component of the diffusion model is the neural network learning to predict?    \n",
    "> 2. How is the predicted noise used in the denoising proceses.   \n",
    "> 3. How are the signal rate and noise rates comptued by the `diffusion_schedule` method used to update the noise image?     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbade84-f6f4-4f88-99e2-c66917efe920",
   "metadata": {},
   "source": [
    "> **Answers:**     \n",
    "> 1.    \n",
    "> 2.     \n",
    "> 3.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b85faf4-f4ef-4ea6-9546-ce7b29f8e438",
   "metadata": {},
   "source": [
    "> **Exercise 11-3::** The code shown below is copied from the `train_step` method of the DiffusionModel class.   "
   ]
  },
  {
   "cell_type": "raw",
   "id": "dafd29c1-cbb4-4e1e-a7a3-f8f584a0c200",
   "metadata": {},
   "source": [
    "        # sample uniform random diffusion times\n",
    "        diffusion_times = keras.random.uniform(\n",
    "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
    "        )\n",
    "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
    "        # mix the images with noises accordingly\n",
    "        noisy_images = signal_rates * images + noise_rates * noises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa7761-6be9-437b-9c6f-57926889808a",
   "metadata": {},
   "source": [
    "> In a few sentances, explain how this code implements the forward steps of the random diffusion process?           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5997b2b6-67ff-486b-938a-c13858bc969e",
   "metadata": {},
   "source": [
    "> **Answer:**       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38ec8b-3145-433b-b8eb-697cf4eda438",
   "metadata": {},
   "source": [
    "> **Exercise 11-4:** Examine the code in the **Training** code cell. What loss function is used, and what error is being learned?              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde60e3-a1d4-4a03-8176-814f358bd4a1",
   "metadata": {},
   "source": [
    "> **Answers:**            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340bdea-eada-4087-a04a-b0374a31a1c1",
   "metadata": {},
   "source": [
    "> **Exercise 11-5:** Examine the squence of generated images produced in the history of the training epochs.These images represent the end product of the denoising Markov chain.\n",
    "> 1. What do the images produced in the first few epochs tell you about the learning of the denoising process parameters?\n",
    "> 2. Given the quality of the images in the laast few epochs what can you say about the neural network's ability to learn the noise parameters, $\\epsilon_\\theta$?      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a33d0c0-016e-4a38-918c-f6c3088f156c",
   "metadata": {},
   "source": [
    "> **Answers:**        \n",
    "> 1.          \n",
    "> 2.       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f044490-55b3-406b-9aa1-72a23a4b436d",
   "metadata": {},
   "source": [
    "> **Exercise 11-6:**  Examine the images produced by the best trained model in the Inference section of the notebook. All of the images are of floweres. However, there is no guidance indicating the images produced should be of flowers.    \n",
    "> 1. Considering the training images, why do you think only flower images are created?\n",
    "> 2. What are the implications of your answer to the above question in terms the distributions required for creating a diffusion image generative model that can create a wide range of images?\n",
    "> 3. What are the limitations you have just discussed have for the general ability of generative diffusion models to produce arbitrary iamges in practice?       \n",
    "> **End of exercise.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f01ad-9ea8-4b01-b8f3-361d9f02a629",
   "metadata": {},
   "source": [
    "> **Answers:**\n",
    "> 1.            \n",
    "> 2.        \n",
    "> 3.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc337e-3ae0-4ffd-bf5d-b00a3b2feab9",
   "metadata": {},
   "source": [
    "> **Exercise 11-7:** Examine the three plots produced from the training metrics and answer the following questions.     \n",
    "> 1. Is the monotonic decrease in noise loss expected given the training algorithm and why?\n",
    "> 2. Image loss measures the difference between the training imaage and the denoising image. This metric is not used to learn the model, but only for monitoring the training. Why does the general shape of the image loss curve closely resemble the noise loss curve?\n",
    "> 3. The kernel inception distance (KDI) curve does not decrease monotonically. Is this behavior reasonable as the model learns and why?\n",
    "> 4. Given the noise loss, image loss and KDI curves does it appear that the training of the model has largely converged?    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8d1f2c-9b94-4b2d-b5d1-1e1cd343c91b",
   "metadata": {},
   "source": [
    "> **Answers:**      \n",
    "> 1.      \n",
    "> 2.          \n",
    "> 3.          \n",
    "> 4.       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657b202-3043-4fe8-8366-2bb1a69aac14",
   "metadata": {},
   "source": [
    "## For Further Exploration     \n",
    "\n",
    "You can find some other examples of constructing and running diffusion models in these examples:       \n",
    "1. [High-performance image generation using Stable Diffusion in KerasCV](https://www.tensorflow.org/tutorials/generative/generate_images_with_stable_diffusion).    \n",
    "2. [Fine-tuning Stable Diffusion](https://keras.io/examples/generative/finetune_stable_diffusion/).      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456bdb12-6b5f-4a6c-a607-a660689c0566",
   "metadata": {},
   "source": [
    "#### Copyright 2024, Stephen F. Elston. All rights reserved.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
